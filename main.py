
import os  # ğŸ—‚ï¸ Importing os module for file operations
import numpy as np  # ğŸ“Š Importing NumPy for numerical operations
import torch  # ğŸ”¥ Importing PyTorch for deep learning
from torch.utils.data import DataLoader  # ğŸšš Importing DataLoader for batching
import torch.nn as nn  # âš™ï¸ Importing neural network module from PyTorch
import torch.optim as optim  # âš¡ Importing optimization algorithms
from sklearn.model_selection import train_test_split  # ğŸ“š Importing function to split data

# Function to predict structure
def predict_structure(model, input_sequence, device):  
    input_ids = tokenize(input_sequence).to(device)  # ğŸ§¬ Tokenizing the input sequence for the model
    with torch.no_grad():  # ğŸš« Disabling gradient computation for inference
        predicted_structure = model(input_ids).cpu().numpy()  # ğŸ§ª Getting predicted structure and moving to CPU
    return predicted_structure  # ğŸ“¥ Returning the predicted structure

# Function to visualize the predicted structure
def visualize_structure(pdb_file, predicted_structure):  
    cmd.load(pdb_file)  # ğŸ“‚ Loading the pdb file for visualization
    for i, (resn, resi, x, y, z) in enumerate(predicted_structure):  # ğŸ”„ Iterating through predicted structure
        cmd.alter(f'resn {resn} and resi {resi}', f'x={x}, y={y}, z={z}')  # ğŸ› ï¸ Altering coordinates of residues
    cmd.show_as('cartoon')  # ğŸ¨ Displaying structure in cartoon representation
    cmd.viewport(800, 600)  # ğŸ–¥ï¸ Setting viewport size
    cmd.zoom('all')  # ğŸ” Zooming into the structure
    cmd.png('predicted_structure.png')  # ğŸ“¸ Saving visualization as PNG
    cmd.delete('all')  # ğŸ—‘ï¸ Deleting all loaded structures from visualization environment

# Main function execution starts here
if __name__ == '__main__':  
    # Load and preprocess data  
    protein_sequences = []  # ğŸ§ª List to store protein sequences
    protein_structures = []  # ğŸ—ï¸ List to store protein structures
    for file in os.listdir('data/'):  # ğŸ“‚ Looping through files in the 'data' directory
        if file.endswith('.fasta'):  # ğŸ“„ Checking if file is a FASTA file
            sequence = open(os.path.join('data/', file), 'r').read().splitlines()[1]  # ğŸ“ Reading sequence line
            protein_sequences.append(sequence)  # â• Adding sequence to list
            pdb_file = os.path.join('data/', file.replace('.fasta', '.pdb'))  # ğŸ§© Defining corresponding PDB file path
            protein_structures.append(extract_structural_features(pdb_file))  # ğŸ—ï¸ Extracting structural features
    protein_sequences = np.array(protein_sequences)  # ğŸ”„ Converting list to NumPy array
    protein_structures = np.array(protein_structures)  # ğŸ”„ Converting list to NumPy array

    # Extract sequence and structural features  
    sequence_features = np.array([extract_sequence_features(seq) for seq in protein_sequences])  # ğŸŒ„ Extracting sequence features
    structural_features = protein_structures  # ğŸ—ï¸ Assigning structural features

    # Split the data into training and validation sets  
    X_train, X_val, y_train, y_val = train_test_split(sequence_features, structural_features, test_size=0.2, random_state=42)  # ğŸ“Š Splitting data

    # Create the PyTorch dataset and dataloader  
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")  # ğŸ’» Selecting device: GPU if available
    train_dataset = ProteinDataset(X_train, y_train, device)  # ğŸ¥— Creating training dataset
    val_dataset = ProteinDataset(X_val, y_val, device)  # ğŸ¥— Creating validation dataset
    train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)  # ğŸšš Creating data loader for training
    val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)  # ğŸšš Creating data loader for validation

    # Define the model, loss function, and optimizer  
    model = ProteinStructureModel(input_size=len(extract_sequence_features('DUMMY')), hidden_size=512, output_size=15, device=device).to(device)  # ğŸ—ï¸ Initializing the model
    criterion = nn.MSELoss()  # ğŸ“‰ Defining loss function (Mean Squared Error)
    optimizer = optim.Adam(model.parameters(), lr=0.001)  # âš¡ Initializing Adam optimizer

    # Train the model  
    num_epochs = 100  # ğŸ” Setting number of epochs
    train_model(model, train_dataloader, criterion, optimizer, num_epochs)  # ğŸ‹ï¸ Training the model

    # Evaluate the model on the validation set  
    val_loss = evaluate_model(model, val_dataloader, criterion)  # ğŸ“‰ Evaluating validation loss
    print(f'Validation Loss: {val_loss}')  # ğŸ“£ Printing validation loss

    # Predict and visualize the structure for a new sequence  
    new_sequence = 'MKTVRQERLKSIVRILERSKEPNPQPGTTHDIVSRWALSTYLNGADFMPVLGFGTYAYPGKITFNEHGRQSIRGNMKDKPVRGAQLANGALRMIPASQWVIRNVSEEVAQLKKNIGIALIKTNNCALADALLDSVPTPSNPPTTEEEKTESNQPEVTCVVVTDSQYALNGNGNEVTMTLHFMFLRLNARGRKTLRSIAFPQTDINLFLNGSLVDGQTGPHKIQGINALCAIHPQYLAKANASWRIFLQSDRYKYWDVNEV'  # ğŸ§¬ Defining new protein sequence
    predicted_structure = predict_structure(model, new_sequence, device)  # ğŸ”® Predicting structure for the new sequence
    visualize_structure('data/new_sequence.pdb', predicted_structure)  # ğŸ¨ Visualizing the predicted structure
